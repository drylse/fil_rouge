{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression,ElasticNet,Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "from numpy import where,unique\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,f1_score,mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pretraite= pd.read_csv('C:\\\\Users\\\\actou\\\\OneDrive\\\\Documents\\\\IODAA\\\\AZOTE\\\\Classification\\\\data_pretraite_J5.csv',sep = ';')\n",
    "df_pretraite.head()\n",
    "df_pretraite.sort_values(by=[\"N20\"],ascending = True)\n",
    "#df_pretraite.isna().sum().describe()\n",
    "\n",
    "df_svm = pd.read_csv('C:\\\\Users\\\\actou\\\\OneDrive\\\\Documents\\\\IODAA\\\\AZOTE\\\\Classification\\\\data_svm_result.csv',sep = ';')\n",
    "df_svm.head()\n",
    "df_svm.sort_values(by=[\"N20\"],ascending = True)\n",
    "#df_svm.isna().sum().describe()\n",
    "\n",
    "df_stat = pd.read_csv('C:\\\\Users\\\\actou\\\\OneDrive\\\\Documents\\\\IODAA\\\\AZOTE\\\\Classification\\\\df_clean_pic_stat.csv',sep = ';')\n",
    "df_stat.head()\n",
    "df_stat.sort_values(by=[\"N20\"],ascending = True)\n",
    "#df_stat.isna().sum().describe()\n",
    "\n",
    "#Liste des variables communes aux trois df\n",
    "var_communes = set(df_pretraite.columns).intersection(set(df_stat.columns)).intersection(set(df_svm.columns))\n",
    "\n",
    "#Liste des variables de proppre à chaque df\n",
    "var_only_df_pretraite = set(df_pretraite.columns) - set(df_stat.columns) - set(df_svm.columns)\n",
    "var_only_df_stat =  set(df_stat.columns) - set(df_pretraite.columns) - set(df_svm.columns)\n",
    "var_only_df_svm = set(df_svm.columns) - set(df_pretraite.columns) - set(df_stat.columns)\n",
    "\n",
    "print('Les variables propres à df_stat sont :',var_only_df_stat)\n",
    "print('Les variables propres à df_svm sont :',var_only_df_svm)\n",
    "print('Les variables propres à df_pretraite sont :',var_only_df_pretraite)\n",
    "\n",
    "#Ajout des colonnes\n",
    "df_pretraite[\"Pic_svm\"] = df_svm[\"Pic\"]\n",
    "df_pretraite[\"Pic_stat\"] = df_stat[\"Pic_stat\"]\n",
    "df_pretraite.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dataframe utilisé pour la suite de ce notebook est **df**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOUVEAU DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pretraite= pd.read_csv('C:\\\\Users\\\\actou\\\\OneDrive\\\\Documents\\\\IODAA\\\\AZOTE\\\\data\\\\data_pretraite.csv',sep = ';')\n",
    "df_pretraite.head()\n",
    "df_pretraite.sort_values(by=[\"N20\"],ascending = True)\n",
    "df_pretraite= df_pretraite.drop([\"Unnamed: 0\"], axis=1)\n",
    "df = df_pretraite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valeurs manquantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     58.000000\n",
       "mean     195.310345\n",
       "std      189.937959\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%      370.000000\n",
       "75%      379.000000\n",
       "max      379.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repartition_val_manquantes(df):\n",
    "    df.isna().sum().to_csv('Données manquantes', index=False)\n",
    "  \n",
    "    ## Répartition des valeurs manquantes \n",
    "    val_NA_0 = len(df.columns[df.isna().sum() == 0].tolist())/len(df.columns)*100\n",
    "    val_NA_0_25 = len(df.columns[df.isna().sum() > 0] & df.columns[df.isna().sum() < 372*0.25])/len(df.columns)*100 ## + de 25 \n",
    "    val_NA_25_50 = len(df.columns[df.isna().sum() > 372*0.25 ] & df.columns[df.isna().sum() < 372*0.5])/len(df.columns)*100 ## + de 25 \n",
    "    val_NA_50_75 = len(df.columns[df.isna().sum() > 372*0.5 ] & df.columns[df.isna().sum() < 372*0.75 ])/len(df.columns)*100 ## + de 25 \n",
    "    val_NA_75_100 = len(df.columns[df.isna().sum() > 373*0.75].tolist())/len(df.columns)*100\n",
    "\n",
    "    values = [val_NA_0, val_NA_0_25,val_NA_75_100]\n",
    "    labels = ['0%',']0 - 25]%', ']75 - 100]%']\n",
    "    \n",
    "    plt.title(\"Répartition des valeurs manquantes par colonne\")\n",
    "    plt.pie(values, labels = labels, autopct='%1.1f%%', startangle=90)\n",
    "    plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enlève les colonnes qui ont au moins une donnée manquantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmv_val_manquantes(df):\n",
    "    df.replace(r'\\s+', np.nan,regex = True)\n",
    "    df= df.dropna(axis = 1)\n",
    "    df.isna().sum().describe()\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repartition_val_manquantes(df)\n",
    "rmv_val_manquantes(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correlations(df,niv_corr):\n",
    "\n",
    "    ''' \n",
    "        Corrélation entre les variables \n",
    "    '''\n",
    "    corr = df.corr()\n",
    "    liste_corr = corr.unstack().sort_values(ascending=False).reset_index()\n",
    "    liste_corr = liste_corr[liste_corr.level_0 != liste_corr.level_1]\n",
    "    liste_corr = liste_corr[liste_corr[0] > niv_corr]\n",
    "    liste_corr = liste_corr.loc[:, ['level_0', 'level_1', 0]]\n",
    "    liste_corr.columns = ['var1', 'var2', 'Niveau  de correlation']\n",
    "    liste_corr\n",
    "\n",
    "    '''\n",
    "      HEATMAP\n",
    "    '''\n",
    "    plt.figure(figsize=(20,10))\n",
    "    sns.heatmap(df.corr(),vmin=-1,vmax=1,center=0,annot=False)\n",
    "    plt.title('Heatmap of Correlations')\n",
    "\n",
    "    '''\n",
    "        Nombre de paires corrélées par niveau de corrélation [0.6 - 1]\n",
    "    ''' \n",
    "    niv_corr = [0.6,0.7,0.75,0.8,0.85,0.9,0.95,1]\n",
    "    liste_nb_paires = []\n",
    "    liste_corr = df.corr().unstack().sort_values(ascending=False).reset_index()\n",
    "    liste_corr = liste_corr[liste_corr.level_0 != liste_corr.level_1]\n",
    "    for i in niv_corr:\n",
    "        liste_corr = liste_corr[liste_corr[0] > i]\n",
    "        liste_nb_paires.append(len(liste_corr))\n",
    "\n",
    "    pd.DataFrame({\"Niveau de corrélation\": niv_corr, 'Nombre de paires':liste_nb_paires})\n",
    "\n",
    "    '''\n",
    "        Liste des paires de variables avec un niveau de correlation : niv_corr\n",
    "    '''\n",
    "    \n",
    "    corr[corr == niv_corr].stack().reset_index()\n",
    "    pairs_corr = corr[corr > 0.8].stack().reset_index().drop_duplicates()\n",
    "    pairs_corr.columns = ['var1','var2','corr']\n",
    "    vars_corr = pairs_corr['var1'].unique().tolist() + pairs_corr['var2'].unique().tolist()\n",
    "    vars_corr = list(set(vars_corr))\n",
    "    print(\"La liste des paires de variables au niveau de corrélation \",niv_corr,\"sont:\",pairs_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_correlations(df,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mois'] = pd.DatetimeIndex(df['Date']).month\n",
    "df['année'] = pd.DatetimeIndex(df['Date']).year\n",
    "df['mois'] = df['mois'].astype('object')\n",
    "df['année'] = df['année'].astype('object')\n",
    "\n",
    "# Afficher le dataframe avec les nouvelles colonnes \"mois\" et \"année\"\n",
    "df = df.drop(columns=['Date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les variables qualitatives sont: ['Bande', 'mois', 'année']\n"
     ]
    }
   ],
   "source": [
    "## Liste des varaibles qualitatives \n",
    "liste_var = list(df.select_dtypes(include=['object']).columns)\n",
    "print(\"Les variables qualitatives sont:\",liste_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodage(df,liste_variable_a_encoder):\n",
    "\n",
    "    '''\n",
    "        Le datset encodé est exporté dans le setwd\n",
    "    ''' \n",
    "    liste_var = liste_variable_a_encoder\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "    for column in liste_var:\n",
    "        one_hot_encoded_df = pd.DataFrame(encoder.fit_transform(df[[column]]))\n",
    "        one_hot_encoded_df.columns = encoder.get_feature_names([column])\n",
    "        df= df.drop([column], axis=1).merge(one_hot_encoded_df, left_index=True, right_index=True)\n",
    "\n",
    "    print(\"La liste des variables après l'encodage, est :\",list(df.columns))\n",
    "    df.to_csv('df_encoded.csv', index=True)\n",
    "    df.info()\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodage(df,liste_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('C:\\\\Users\\\\actou\\\\OneDrive\\\\Documents\\\\IODAA\\\\AZOTE\\\\Classification\\\\df_encoded.csv',sep = ',')\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre de pics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nombre_pics(df,nom_var_pic,nom_Pic_OUI):\n",
    "    '''\n",
    "        Compter le nombre de pics et de non-pics\n",
    "    '''\n",
    "    liste_un = len(np.where(df[nom_var_pic] == nom_Pic_OUI)[0].tolist())\n",
    "    liste_zero = len(df[nom_var_pic] - liste_un)\n",
    "    size_group = [liste_un,liste_zero]\n",
    "\n",
    "    '''\n",
    "        Tracer Pie Chart \n",
    "    ''' \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.pie(size_group,labels=(\"Pic\",\"Pas_pic\"),autopct='%1.1f%%',colors=['green','blue'])\n",
    "    plt.title(\"Répartition Stat\")\n",
    "    my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "    p=plt.gcf()\n",
    "    p.gca().add_artist(my_circle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisation_and_split(X,y,proportion_set_test):\n",
    "    X =pd.DataFrame(X)\n",
    "    y= pd.DataFrame(y)\n",
    "    Min_Max = MinMaxScaler()\n",
    "    X = Min_Max.fit_transform(X)\n",
    "    y= Min_Max.fit_transform(y.values.reshape(-1,1))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=proportion_set_test,random_state=0)\n",
    "\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tableau résultats selection de variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats_selection_var = pd.DataFrame(columns=['Méthode','RFC','Pic','Accuracy','MSE', 'R2score'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthode de sélection (filter & Wrapper)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifier la condition d'ireprésentabilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verif_condition_ireprésentabilite_METHODE1(X,y):\n",
    "    model = sm.OLS(y, X) # Define the linear regression model\n",
    "    ols_results = model.fit() # Estimate the OLS model\n",
    "    coefs = ols_results.params # Assess the coefficients of the linear regression model\n",
    "    strong_irrepresentability_code = np.mean(np.abs(coefs)) # Compute the strong irrepresentability code\n",
    "    corr_matrix = np.corrcoef(X, rowvar=False) # Calculate the correlation matrix between the features\n",
    "    avg_abs_corr = np.mean(np.abs(corr_matrix))  # Compute the average absolute correlation\n",
    "    representability_condition = strong_irrepresentability_code + avg_abs_corr # Calculate the representability condition\n",
    "    if representability_condition < 1: # Determine if the representability condition is satisfied\n",
    "        print(\"The representability condition is satisfied.\")\n",
    "    else:\n",
    "        print(\"The representability condition is not satisfied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verif_condition_ireprésentabilite_METHODE2(X):\n",
    "    n_vars = X.shape[1]# Get the number of variables\n",
    "    results = []# Create a list to store the results\n",
    "    for i in range(n_vars):# Loop through each variable\n",
    "        corr = np.corrcoef(X[:, i], X[:, -1])[0, 1]# Calculate the correlation between each variable and the target\n",
    "        if corr != 0:# If the correlation is not 0, then the variable is not strongly irrepresentable\n",
    "            results.append(False)\n",
    "            print(\"The condition is not satisfied\")\n",
    "        else:\n",
    "            results.append(True)  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_variables_LASSO_RFC(X_train,X_test,y_test,y_train,penalty):\n",
    "    ''' \n",
    "        Cette fonction permet de rélaiser une selection de varaibles avec la méthode LASSO et de prédire les cklasses des oics avec un RandomForestClassifieur\n",
    "        Les résultats sont directement implémentés dans le teableau final \n",
    "    '''\n",
    "\n",
    "    ''' \n",
    "        MEILLEUR PARAMETRE ALPHA\n",
    "    ''' \n",
    "    alphas = [0.0005, 0.001, 0.01, 0.03, 0.05, 0.1,0.5,1,5,10]\n",
    "    liste_score,liste_alpha =  [],[]\n",
    "    \n",
    "    for a in alphas:\n",
    "        model = Lasso(alpha=a)\n",
    "        model.fit(X_train, y_train)\n",
    "        liste_score.append(model.score(X, y))\n",
    "        liste_alpha.append(a)\n",
    "        data = pd.DataFrame({\"Alpha\":liste_alpha,\"R2\":liste_score})\n",
    "        max_r2 = data[\"R2\"].idxmax()\n",
    "        max_alpha = data.at[max_r2, 'colonne 2']\n",
    "   \n",
    "\n",
    "    '''\n",
    "        Selection variables avec LASSO regularisée \n",
    "    '''\n",
    "    model_lasso = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n",
    "    model_lasso .fit(X_train, np.ravel(y_train,order='C'))\n",
    "    model_lasso .get_support()\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "\n",
    "    ## Variables selectionnées \n",
    "    variables_select= X_train.columns[(model_lasso .get_support())]\n",
    "    \n",
    "    ### Liste des variables conservées\n",
    "    X_train_selected = model.transform(X_train)\n",
    "    X_test_selected = model.transform(X_test)\n",
    "    X_train_selected.shape, X_test_selected.shape\n",
    "\n",
    "    ### Liste des variables supprimées\n",
    "    variables_suppr= X_train.columns[(model.estimator_.coef_ == 0).ravel().tolist()]\n",
    "\n",
    "    '''\n",
    "         SANS RandomForest pour prédire les résultats \n",
    "    ''' \n",
    "    y_pred_sans_RFC = model_lasso.predict(X_test)\n",
    "    resultats_selection_var = resultats_selection_var.append({'Méthode': penalty, 'RFC':'NON', 'Pic': ' / ', 'Nombre total de variables': '/ ', 'Nombre var selectionnnées': '/', 'Nombre de varaiables supprimées': 'x', 'Accuracy': accuracy_score(y_test,  y_pred_sans_RFC ), 'MSE': mean_squared_error(y_test,  y_pred_sans_RFC ), 'R2score': r2_score(y_test,  y_pred_sans_RFC )}, ignore_index=True)\n",
    "\n",
    "    ''' \n",
    "        AVEC Random Forest pour prédire les résultats\n",
    "    ''' \n",
    "    clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "    clf.fit(X_train_selected,np.ravel(y_train,order='C'))\n",
    "    y_pred= clf.predict(X_test_selected)\n",
    "    \n",
    "    resultats_selection_var = resultats_selection_var.append({'Méthode': penalty,'RFC':'OUI', 'Pic': ' / ', 'Nombre total de variables': '/ ', 'Nombre var selectionnnées': '/', 'Nombre de varaiables supprimées': 'x', 'Accuracy': accuracy_score(y_test, y_pred), 'MSE': mean_squared_error(y_test, y_pred), 'R2score': r2_score(y_test, y_pred)}, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELASTIC NET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_variables_ELASTICNET_RFC(X_train,X_test,y_test,y_train,penalty):\n",
    "    ''' \n",
    "        MEILLEUR PARAMETRE ALPHA & L1 ratio \n",
    "    ''' \n",
    "    alphas = [0.0005, 0.001, 0.01, 0.03, 0.05, 0.1,0.5]\n",
    "    l1_ratios = [1, 0.9, 0.8, 0.7, 0.5,0.4,0.3,0.2,0.1]\n",
    "    liste_score,liste_alpha,liste_L1= [],[],[]\n",
    "\n",
    "    for alpha in alphas:\n",
    "        for l1_ratio in l1_ratios:\n",
    "            elastic_net = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "            elastic_net.fit(X_train, y_train)\n",
    "            liste_score.append(elastic_net.score(X_test, y_test))\n",
    "            liste_alpha.append(alpha)\n",
    "            liste_L1.append(l1_ratio)\n",
    "            data = pd.DataFrame({\"Alpha\":liste_alpha,\"L1_ratio\":l1_ratio,\"R2\":liste_score}) \n",
    "            max_r2 = data[\"R2\"].idxmax()\n",
    "            max_alpha = data.at[max_r2, 'Alpha']\n",
    "            max_l1ratio = data.at[max_r2, 'L1_ratio']\n",
    "\n",
    "\n",
    "# Selection variables avec ELASTICNET\n",
    "    '''\n",
    "        Selection variables avec ELASTIC\n",
    "    '''\n",
    "    model_lasso = SelectFromModel(LogisticRegression(C=1, penalty='elasticnet',l1_ratio=max_l1ratio))\n",
    "    model_lasso .fit(X_train, np.ravel(y_train,order='C'))\n",
    "    model_lasso .get_support()\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "\n",
    "    ## Variables selectionnées \n",
    "    variables_select= X_train.columns[(model_lasso .get_support())]\n",
    "    \n",
    "    ### Liste des variables conservées\n",
    "    X_train_selected = model.transform(X_train)\n",
    "    X_test_selected = model.transform(X_test)\n",
    "    X_train_selected.shape, X_test_selected.shape\n",
    "\n",
    "    ### Liste des variables supprimées\n",
    "    variables_suppr= X_train.columns[(model.estimator_.coef_ == 0).ravel().tolist()]\n",
    "\n",
    "    '''\n",
    "         SANS RandomForest pour prédire les résultats \n",
    "    ''' \n",
    "    y_pred_sans_RFC = model_lasso.predict(X_test)\n",
    "    resultats_selection_var = resultats_selection_var.append({'Méthode': penalty,'RFC': 'NON','Pic': ' / ', 'Nombre total de variables': '/ ', 'Nombre var selectionnnées': '/', 'Nombre de varaiables supprimées': 'x', 'Accuracy': accuracy_score(y_test,  y_pred_sans_RFC ), 'MSE': mean_squared_error(y_test,  y_pred_sans_RFC ), 'R2score': r2_score(y_test,  y_pred_sans_RFC )}, ignore_index=True)\n",
    "\n",
    "    ''' \n",
    "        AVEC Random Forest pour prédire les résultats\n",
    "    ''' \n",
    "    clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "    clf.fit(X_train_selected,np.ravel(y_train,order='C'))\n",
    "    y_pred= clf.predict(X_test_selected)\n",
    "    \n",
    "    resultats_selection_var = resultats_selection_var.append({'Méthode': penalty,'RFC': 'OUI', 'Pic': ' / ', 'Nombre total de variables': '/ ', 'Nombre var selectionnnées': '/', 'Nombre de varaiables supprimées': 'x', 'Accuracy': accuracy_score(y_test, y_pred), 'MSE': mean_squared_error(y_test, y_pred), 'R2score': r2_score(y_test, y_pred)}, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression logistique + RFE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_regression_rfe(X_train,X_test,y_test,y_train,nb_var):\n",
    "\n",
    "    '''\n",
    "        Cette fonction renvoie \n",
    "        - Les performances de la regression logistique dans la prédiction \n",
    "        - Les n variables qui composent le modèle \n",
    "\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "        Modèle\n",
    "    '''\n",
    "    lr= LogisticRegression()\n",
    "    Nb_var_selected = 10 \n",
    "    rfe = RFE(lr, n_features_to_select = nb_var,step=1)\n",
    "    rfe = rfe.fit(X_train, y_train)\n",
    "    y_pred = rfe.predict(X_test)\n",
    "\n",
    "    '''\n",
    "        Performances\n",
    "    '''\n",
    "    resultats_LOG_REG_RFE= pd.DataFrame({\"Measure\": [\"Accuracy\", \"Mean Squared Error\",\"R2 Score\"],\"Reg_LOGISTIQUE + RFE - STAT\": [accuracy_score(y_test, y_pred),mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred)]})\n",
    "    resultats_LOG_REG_RFE.round(2)\n",
    "\n",
    "    '''\n",
    "        Variables selectionnées   \n",
    "    '''\n",
    "    RFE_result =  pd.DataFrame({\"Variables\":pd.DataFrame(df).columns,\"RFE ranking\":rfe.ranking_.tolist()})\n",
    "    RFE_result.sort_values(by=[\"RFE ranking\"],ascending = True)\n",
    "    RFE_result[RFE_result[\"RFE ranking\"] == 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBRRROOUUIILLOONN  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "# Selection variables avec LASSO\n",
    "model = Lasso(alpha = 0.0005)\n",
    "model.fit(X_train_SVM, np.ravel(y_train_SVM,order='C'))\n",
    "y_pred_sans = model.predict(X_test_SVM)\n",
    "\n",
    "# Get the name of the selected variables\n",
    "X_train_SVM = pd.DataFrame(X_train_SVM)\n",
    "X_test_SVM = pd.DataFrame(X_test_SVM)\n",
    "selected_vars = X_train_SVM.columns[(model.coef_ != 0).ravel().tolist()]\n",
    "\n",
    "# Predict the performance of the classification on the y_test\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "clf.fit(X_train_stat[selected_vars],(pd.DataFrame(y_train_stat)).values.ravel())\n",
    "y_pred = clf.predict(X_test_SVM[selected_vars])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "alphas = [0.0005, 0.001, 0.01, 0.03, 0.05, 0.1,0.5]\n",
    "l1_ratios = [1, 0.9, 0.8, 0.7, 0.5,0.4,0.3,0.2,0.1]\n",
    "liste_score,liste_alpha,liste_L1, liste_L2= [],[],[],[]\n",
    "\n",
    "for alpha in alphas:\n",
    "  for l1_ratio in l1_ratios:\n",
    "      elastic_net = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "      elastic_net.fit(X_train_stat, y_train_stat)\n",
    "      liste_score.append(elastic_net.score(X_test_stat, y_test_stat))\n",
    "      liste_alpha.append(alpha)\n",
    "      liste_L1.append(l1_ratio)\n",
    "      liste_L2.append(l2_ratio)\n",
    "\n",
    "pd.DataFrame({\"Alpha\":liste_alpha,\"L1_ratio\":l1_ratio,\"R2\":liste_score})\n",
    "\n",
    "# Selection variables avec ELASTICNET\n",
    "model = ElasticNet(alpha=0.0005, l1_ratio=0.1)\n",
    "model.fit(X_train_stat, np.ravel(y_train_stat,order='C'))\n",
    "y_pred_sans_stat = model.predict(X_test_stat)\n",
    "\n",
    "# Get the name of the selected variables\n",
    "X_train_stat = pd.DataFrame(X_train_stat)\n",
    "X_test_stat = pd.DataFrame(X_test_stat)\n",
    "selected_vars = X_train_stat.columns[(model.coef_ != 0).ravel().tolist()]\n",
    "\n",
    "# Predict the performance of the classification on the y_test\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "clf.fit(X_train_stat[selected_vars],np.ravel(y_train_stat,order='C'))\n",
    "y_pred_stat = clf.predict(X_test_stat[selected_vars])\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison des résultats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liste de variables selectionnées avec LASSO communes aux deux types de pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_commune_variables_LASSO = []\n",
    "var_ITK, var_meteo, var_Ntraj = 0,0,0\n",
    "\n",
    "# ouvrir et récupérer les colonnes des fichiers\n",
    "df_ITK = pd.read_excel('ITK_TrajectOire.xlsx')\n",
    "df_meteo = pd.read_excel('meteo_2017_2022.xlsx')\n",
    "df_Ntraj= pd.read_excel('Data_Ntraj.xlsx')\n",
    "\n",
    "for i in liste_col_LASSO_selectionnees_STAT:\n",
    "    if i in liste_col_selectionnees_SVM:\n",
    "        liste_commune_variables_LASSO.append(i)\n",
    "\n",
    "print(len(liste_commune_variables_LASSO))\n",
    "\n",
    "for i in liste_commune_variables_LASSO:\n",
    "    if i in list(df_meteo.columns):\n",
    "\t    var_meteo +=1\n",
    "    if i in list(df_Ntraj.columns):\n",
    "\t    var_Ntraj +=1 \n",
    "\n",
    "var_ITK = len(liste_commune_variables_LASSO) -  var_meteo - var_Ntraj\n",
    "\n",
    "## Graph \n",
    "labels = ['ITK', 'Météo', 'Ntraj']\n",
    "sizes = [var_ITK, var_meteo, var_Ntraj]\n",
    "colors = ['red', 'green', 'yellow']\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.legend(labels, loc=\"best\")\n",
    "plt.axis('equal')\n",
    "plt.title(\"Répartition des variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liste de variables selectionnées avec ELASTIC_NET communes aux deux types de pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_commune_variables_EN = []\n",
    "var_ITK, var_meteo, var_Ntraj = 0,0,0\n",
    "\n",
    "for i in liste_col_ELASTICNET_STAT:\n",
    "    if i in liste_col_ELASTICNET_SVM:\n",
    "        liste_commune_variables_EN.append(i)\n",
    "\n",
    "for i in liste_commune_variables_EN:\n",
    "    if i in list(df_meteo.columns):\n",
    "\t    var_meteo +=1\n",
    "    if i in list(df_Ntraj.columns):\n",
    "\t    var_Ntraj +=1 \n",
    "\n",
    "var_ITK = len(liste_commune_variables_EN) -  var_meteo - var_Ntraj\n",
    "\n",
    "## Graph \n",
    "labels = ['ITK', 'Météo', 'Ntraj']\n",
    "sizes = [var_ITK, var_meteo, var_Ntraj]\n",
    "colors = ['red', 'green', 'yellow']\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "plt.legend(labels, loc=\"best\")\n",
    "plt.axis('equal')\n",
    "plt.title(\"Répartition des variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STAT \n",
    "liste_commune_variables_PIC_STAT = []\n",
    "\n",
    "for i in liste_col_LASSO_selectionnees_STAT:\n",
    "    if i in RFE_result_stat[\"Variables STAT\"]:\n",
    "        liste_commune_variables_PIC_STAT.append(i)\n",
    "\n",
    "print(len(liste_commune_variables_PIC_STAT))\n",
    "\n",
    "### SVM \n",
    "liste_commune_variables_PIC_SVM= []\n",
    "\n",
    "for i in liste_col_selectionnees_SVM:\n",
    "    if i in RFE_result_svm[\"Variables SVM\"]:\n",
    "        liste_commune_variables_PIC_SVM.append(i)\n",
    "\n",
    "print(len(liste_commune_variables_PIC_SVM))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "404d4b4449c415f353872e970a2782c513d076429a61a6054f5f7db0dbede263"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
